# A1 - Estimation Theory, Fisher Information, CRLB

### Overview
This assignment focuses on **Estimation Theory**, covering topics such as **log-likelihood functions**, **Fisher Information**, **Cramér-Rao Lower Bound (CRLB)**, and **efficiency** of estimators. The tasks involved theoretical derivations and implementing these concepts to evaluate the properties of estimators in statistical models.

### Key Tasks

- **Log-Likelihood and Estimators**  
  - Implemented the log-likelihood function for Gaussian data and tested it with different values of \(\sigma\).
  - Derived the **unbiasedness** of the sample mean as an estimator for the population mean \(\mu\).

- **Fisher Information and CRLB**  
  - Computed **Fisher Information** for \(\mu\) and confirmed that the **Cramér-Rao Lower Bound** is reached, proving the efficiency of the sample mean estimator.
  - Verified the variance of the estimator and compared it to the CRLB, showing that the sample mean is an **efficient estimator**.

- **Unbiasedness and Efficiency**  
  - Showed that the arithmetic mean estimator for \(\mu\) is unbiased.
  - Checked the efficiency of the estimator by proving that its variance equals the CRLB.
  
---